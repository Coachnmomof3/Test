{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Lambda, Input, AveragePooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random\n",
    "#import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Covid', 'Edema', 'Enlarged_Cardiomediastinum', 'Fracture', 'Lung_Lesion', 'Lung_Opacity', 'No_Finding', 'Pleural_Other', 'Pneumonia', 'Pneumothorax', 'Support_Devices']\n"
     ]
    }
   ],
   "source": [
    "# Check filenames \n",
    "image_names=list(os.listdir(\"Images\"))\n",
    "image_names.sort()\n",
    "print(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No_Finding                    198\n",
       "Covid                         184\n",
       "Pneumothorax                  164\n",
       "Lung_Opacity                  156\n",
       "Edema                         155\n",
       "Support_Devices               154\n",
       "Consolidation                 145\n",
       "Enlarged_Cardiomediastinum    143\n",
       "Atelectasis                   143\n",
       "Fracture                      142\n",
       "Cardiomegaly                  136\n",
       "Lung_Lesion                   127\n",
       "Pneumonia                     118\n",
       "Pleural_Other                  99\n",
       "Name: condition, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directory with Atelectasis\n",
    "atele_dir=os.path.join(\"Images/Atelectasis\")\n",
    "df =pd.DataFrame.from_records({\"file_name\":os.listdir(atele_dir),\"condition\": \"Atelectasis\"})\n",
    "for f in image_names[2:]:\n",
    "    folder_path=\"Images/\" + f\n",
    "    temp_df= pd.DataFrame.from_records({\"file_name\":os.listdir(folder_path),\"condition\": f })\n",
    "    df=df.append(temp_df)\n",
    "    \n",
    "df[\"condition\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Covid                         184\n",
       "Pneumothorax                  164\n",
       "Lung_Opacity                  156\n",
       "Edema                         155\n",
       "Support_Devices               154\n",
       "No_Finding                    150\n",
       "Consolidation                 145\n",
       "Atelectasis                   143\n",
       "Enlarged_Cardiomediastinum    143\n",
       "Fracture                      142\n",
       "Lung_Lesion                   127\n",
       "Pneumonia                     118\n",
       "Pleural_Other                  99\n",
       "Name: condition, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# balance classes - random Random Sampling No_Finding\n",
    "df_no_finding = df[df[\"condition\"]==\"No_Finding\"].sample(n=150, random_state=42)\n",
    "df_balanced = df[df[\"condition\"]!=\"No_Finding\"].append(df_no_finding)\n",
    "df_balanced[\"condition\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2642 images belonging to 14 classes.\n",
      "Found 1122 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height=200,200\n",
    "batch_size=128\n",
    "\n",
    "data_dir = \"Images/\"\n",
    "\n",
    "# Rescale images \n",
    "datagen= ImageDataGenerator(rescale=1/255,validation_split=.3,rotation_range=20,\n",
    "                           shear_range=.2,width_shift_range=0.1,height_shift_range=0.1,zoom_range=0.2)\n",
    "\n",
    "# Flow training images in batches of 128 using train_data \n",
    "train_generator= datagen.flow_from_directory(\n",
    "                data_dir,\n",
    "                target_size=(img_width,img_height),\n",
    "                batch_size=batch_size,\n",
    "                subset=\"training\",\n",
    "                class_mode=\"categorical\", \n",
    "                classes= [\"Covid\", \"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"Enlarged_Cardiomediastinum\", \"Fracture\", \n",
    "                \"Lung_Lesion\", \"Lung_Opacity\", \"No_Finding\", \"Pleural_Other\", \"Pneumonia\", \"Pneumothorax\", \"Support_Devices\"],\n",
    "                shuffle=True, seed=30)\n",
    "\n",
    "\n",
    "# train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#   data_dir,\n",
    "#   validation_split=0.2,\n",
    "#   subset=\"training\",\n",
    "#   seed=123,\n",
    "#   image_size=(img_height, img_width),\n",
    "#   batch_size=batch_size)\n",
    "\n",
    "# # Flow test images in \n",
    "\n",
    "\n",
    "# val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#   data_dir,\n",
    "#   validation_split=0.2,\n",
    "#   subset=\"validation\",\n",
    "#   seed=123,\n",
    "#   image_size=(img_height, img_width),\n",
    "#   batch_size=batch_size)\n",
    "\n",
    "datagen2=ImageDataGenerator(rescale=1/255,validation_split=.3)\n",
    "\n",
    "test_generator=datagen2.flow_from_directory(\n",
    "                data_dir,\n",
    "                target_size=(img_width,img_height),\n",
    "                batch_size=batch_size,\n",
    "                classes= [\"Covid\", \"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"Enlarged_Cardiomediastinum\", \"Fracture\", \n",
    "                \"Lung_Lesion\", \"Lung_Opacity\", \"No_Finding\", \"Pleural_Other\", \"Pneumonia\", \"Pneumothorax\", \"Support_Devices\"],\n",
    "                class_mode=\"categorical\", subset=\"validation\", shuffle=True, seed=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATE MODEL 1\n",
    "classifier= Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), input_shape=(200,200,3),activation='relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "classifier.add(Conv2D(32, (3,3), activation=\"relu\"))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(units=128, activation=\"relu\"))\n",
    "classifier.add(Dense(units=14, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-6212f0520e27>:15: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/3\n",
      "20/20 [==============================] - 38s 2s/step - loss: 2.3490 - accuracy: 0.4821 - val_loss: 1.8941 - val_accuracy: 0.5273\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 33s 2s/step - loss: 1.9176 - accuracy: 0.5008 - val_loss: 2.0185 - val_accuracy: 0.4648\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 37s 2s/step - loss: 1.7582 - accuracy: 0.5024 - val_loss: 1.7980 - val_accuracy: 0.5195\n"
     ]
    }
   ],
   "source": [
    "# MODEL 1\n",
    "\n",
    "classifier.compile(\n",
    "  optimizer='adam',\n",
    "  loss=\"categorical_crossentropy\",\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "total_sample= train_generator.n\n",
    "batch_size=128\n",
    "\n",
    "\n",
    "history= classifier.fit_generator(\n",
    "            train_generator, steps_per_epoch=int(total_sample/batch_size),\n",
    "            epochs=3,\n",
    "            validation_data=test_generator, \n",
    "            validation_steps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2\n",
    "# GENERATE MODEL\n",
    "classifier= Sequential()\n",
    "\n",
    "# First convolution layer\n",
    "classifier.add(Conv2D(32, (3,3), input_shape=(200,200,3),activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Second convolution layer\n",
    "classifier.add(Conv2D(64,(3,3),activation=\"relu\"))\n",
    "classifier.add(Dropout(0.1))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Third convolution layer\n",
    "classifier.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Fourth convolution layer\n",
    "classifier.add(Conv2D(128, (3,3), activation=\"relu\"))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Fifth convolution layer\n",
    "classifier.add(Conv2D(128, (3,3), activation=\"relu\"))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# classifier.add(Conv2D(256, (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "# classifier.add(Dropout(0.2))\n",
    "# classifier.add(BatchNormalization())\n",
    "# classifier.add(MaxPooling2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "# Flatten the results to feed into a dense layer\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# 128 neuron in the fully-connected layer\n",
    "classifier.add(Dense(units = 128 , activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "# 14 output neurons for 14 classes with the softmax activation\n",
    "classifier.add(Dense(units = 14 , activation = 'sigmoid'))\n",
    "\n",
    "# # Flatten the results to feed into a dense layer\n",
    "# classifier.add(Flatten())\n",
    "\n",
    "# # 128 neuron in the fully-connected layer\n",
    "# classifier.add(Dense(128, activation=\"relu\"))\n",
    "\n",
    "# # 14 output neurons for 14 classes with the softmax activation\n",
    "# classifier.add(Dense(14, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "20/20 [==============================] - 83s 4s/step - loss: 2.2853 - accuracy: 0.4976 - val_loss: 2.5555 - val_accuracy: 0.0820\n",
      "Epoch 2/3\n",
      "20/20 [==============================] - 79s 4s/step - loss: 1.9771 - accuracy: 0.5286 - val_loss: 2.9491 - val_accuracy: 0.0430\n",
      "Epoch 3/3\n",
      "20/20 [==============================] - 84s 4s/step - loss: 1.8877 - accuracy: 0.5418 - val_loss: 5.2668 - val_accuracy: 0.0469\n"
     ]
    }
   ],
   "source": [
    "# Model 2, with augmentation\n",
    "classifier.compile(\n",
    "  optimizer='adam',\n",
    "  loss=\"categorical_crossentropy\",\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "total_sample= train_generator.n\n",
    "batch_size=128\n",
    "\n",
    "\n",
    "history= classifier.fit_generator(\n",
    "            train_generator, steps_per_epoch=int(total_sample/batch_size),\n",
    "            epochs=3,\n",
    "            validation_data=test_generator, \n",
    "            validation_steps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "### changed to activation function softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3\n",
    "# GENERATE MODEL\n",
    "classifier= Sequential()\n",
    "\n",
    "# First convolution layer\n",
    "classifier.add(Conv2D(32, (3,3), input_shape=(200,200,3),activation='relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Second convolution layer\n",
    "classifier.add(Conv2D(32,(3,3),activation=\"relu\"))\n",
    "classifier.add(Dropout(0.1))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# # Third convolution layer\n",
    "# classifier.add(Conv2D(64, (3,3), activation=\"relu\"))\n",
    "# classifier.add(BatchNormalization())\n",
    "# classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# classifier.add(Conv2D(256, (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "# classifier.add(Dropout(0.2))\n",
    "# classifier.add(BatchNormalization())\n",
    "# classifier.add(MaxPooling2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "# Flatten the results to feed into a dense layer\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# 128 neuron in the fully-connected layer\n",
    "classifier.add(Dense(128 , activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "# 14 output neurons for 14 classes with the softmax activation\n",
    "classifier.add(Dense(14 , activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "20/20 [==============================] - 61s 3s/step - loss: 1.9142 - accuracy: 0.5434 - val_loss: 2.2040 - val_accuracy: 0.4982\n",
      "Epoch 2/30\n",
      "20/20 [==============================] - 60s 3s/step - loss: 1.8901 - accuracy: 0.5430 - val_loss: 1.8002 - val_accuracy: 0.5455\n",
      "Epoch 3/30\n",
      "20/20 [==============================] - 59s 3s/step - loss: 1.9470 - accuracy: 0.5390 - val_loss: 1.7595 - val_accuracy: 0.5410\n",
      "Epoch 4/30\n",
      "20/20 [==============================] - 60s 3s/step - loss: 1.9805 - accuracy: 0.5422 - val_loss: 3.1294 - val_accuracy: 0.5071\n",
      "Epoch 5/30\n",
      "20/20 [==============================] - 59s 3s/step - loss: 1.9088 - accuracy: 0.5402 - val_loss: 2.7816 - val_accuracy: 0.5027\n",
      "Epoch 6/30\n",
      "20/20 [==============================] - 59s 3s/step - loss: 1.8801 - accuracy: 0.5473 - val_loss: 2.8427 - val_accuracy: 0.5071\n",
      "Epoch 7/30\n",
      "20/20 [==============================] - 59s 3s/step - loss: 1.8817 - accuracy: 0.5505 - val_loss: 3.1637 - val_accuracy: 0.5071\n",
      "Epoch 8/30\n",
      "20/20 [==============================] - 59s 3s/step - loss: 1.9101 - accuracy: 0.5430 - val_loss: 1.8273 - val_accuracy: 0.5499\n",
      "Epoch 9/30\n",
      "20/20 [==============================] - 59s 3s/step - loss: 1.8751 - accuracy: 0.5414 - val_loss: 1.7537 - val_accuracy: 0.5455\n",
      "Epoch 10/30\n",
      "20/20 [==============================] - 59s 3s/step - loss: 1.9433 - accuracy: 0.5370 - val_loss: 1.8226 - val_accuracy: 0.5321\n",
      "Epoch 11/30\n",
      "20/20 [==============================] - 59s 3s/step - loss: 1.8834 - accuracy: 0.5382 - val_loss: 1.7855 - val_accuracy: 0.5374\n",
      "Epoch 12/30\n",
      "20/20 [==============================] - 81s 4s/step - loss: 1.8757 - accuracy: 0.5422 - val_loss: 1.7880 - val_accuracy: 0.5535\n",
      "Epoch 13/30\n",
      "20/20 [==============================] - 66s 3s/step - loss: 1.8497 - accuracy: 0.5489 - val_loss: 1.7057 - val_accuracy: 0.5544\n",
      "Epoch 14/30\n",
      "20/20 [==============================] - 64s 3s/step - loss: 1.8438 - accuracy: 0.5461 - val_loss: 1.8127 - val_accuracy: 0.5428\n",
      "Epoch 15/30\n",
      "20/20 [==============================] - 59s 3s/step - loss: 1.8715 - accuracy: 0.5418 - val_loss: 1.7802 - val_accuracy: 0.5490\n",
      "Epoch 16/30\n",
      "20/20 [==============================] - 59s 3s/step - loss: 1.8567 - accuracy: 0.5449 - val_loss: 1.7331 - val_accuracy: 0.5535\n",
      "Epoch 17/30\n",
      "20/20 [==============================] - 58s 3s/step - loss: 1.8316 - accuracy: 0.5434 - val_loss: 1.7288 - val_accuracy: 0.5535\n",
      "Epoch 18/30\n",
      "20/20 [==============================] - 58s 3s/step - loss: 1.8572 - accuracy: 0.5418 - val_loss: 1.8184 - val_accuracy: 0.5294\n",
      "Epoch 19/30\n",
      "20/20 [==============================] - 59s 3s/step - loss: 1.8731 - accuracy: 0.5398 - val_loss: 2.1370 - val_accuracy: 0.5223\n",
      "Epoch 20/30\n",
      "20/20 [==============================] - 58s 3s/step - loss: 1.8588 - accuracy: 0.5493 - val_loss: 1.7537 - val_accuracy: 0.5446\n",
      "Epoch 21/30\n",
      "20/20 [==============================] - 58s 3s/step - loss: 1.8373 - accuracy: 0.5382 - val_loss: 1.9145 - val_accuracy: 0.5472\n",
      "Epoch 22/30\n",
      "20/20 [==============================] - 59s 3s/step - loss: 1.8186 - accuracy: 0.5477 - val_loss: 1.7740 - val_accuracy: 0.5428\n",
      "Epoch 23/30\n",
      "20/20 [==============================] - 58s 3s/step - loss: 1.8361 - accuracy: 0.5457 - val_loss: 1.9216 - val_accuracy: 0.5490\n",
      "Epoch 24/30\n",
      "20/20 [==============================] - 59s 3s/step - loss: 1.8533 - accuracy: 0.5469 - val_loss: 1.9069 - val_accuracy: 0.5553\n",
      "Epoch 25/30\n",
      "20/20 [==============================] - 171s 9s/step - loss: 1.9166 - accuracy: 0.5386 - val_loss: 2.1087 - val_accuracy: 0.5455\n",
      "Epoch 26/30\n",
      "20/20 [==============================] - 60s 3s/step - loss: 2.0411 - accuracy: 0.5374 - val_loss: 89.3279 - val_accuracy: 0.0490\n",
      "Epoch 27/30\n",
      "20/20 [==============================] - 60s 3s/step - loss: 1.9090 - accuracy: 0.5394 - val_loss: 55.7888 - val_accuracy: 0.0695\n",
      "Epoch 28/30\n",
      "20/20 [==============================] - 59s 3s/step - loss: 1.8263 - accuracy: 0.5457 - val_loss: 3.2703 - val_accuracy: 0.4938\n",
      "Epoch 29/30\n",
      "20/20 [==============================] - 58s 3s/step - loss: 1.8185 - accuracy: 0.5453 - val_loss: 2.3209 - val_accuracy: 0.4955\n",
      "Epoch 30/30\n",
      "20/20 [==============================] - 59s 3s/step - loss: 1.8209 - accuracy: 0.5449 - val_loss: 2.2482 - val_accuracy: 0.5428\n"
     ]
    }
   ],
   "source": [
    "# Model 3, with augmentation\n",
    "classifier.compile(\n",
    "  optimizer='adam',\n",
    "  loss=\"categorical_crossentropy\",\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "total_valsample=test_generator.n\n",
    "total_sample= train_generator.n\n",
    "batch_size=128\n",
    "\n",
    "history= classifier.fit_generator(\n",
    "            train_generator, steps_per_epoch=int(total_sample/batch_size),\n",
    "            epochs=30,\n",
    "            validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2893 images belonging to 3 classes.\n",
      "Found 1238 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height=200,200\n",
    "batch_size=128\n",
    "\n",
    "data_dir = \"Database/\"\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,validation_split=.3,\n",
    "                             zoom_range=0.2,horizontal_flip=True,\n",
    "                                preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator= datagen.flow_from_directory(\n",
    "                data_dir,\n",
    "                target_size=(64,64),\n",
    "                batch_size=batch_size,\n",
    "                subset=\"training\",\n",
    "                class_mode=\"categorical\", \n",
    "                classes= [\"COVID19\", \"NORMAL\",\"Viral_Pneumonia\"],\n",
    "                shuffle=False, seed=30)\n",
    "\n",
    "datagen2=ImageDataGenerator(rescale=1/255,validation_split=.3,\n",
    "                           preprocessing_function=preprocess_input)\n",
    "\n",
    "test_generator=datagen2.flow_from_directory(\n",
    "                data_dir,\n",
    "                target_size=(64,64),\n",
    "                batch_size=batch_size,\n",
    "                classes= [\"COVID19\", \"NORMAL\",\"Viral_Pneumonia\"],\n",
    "                class_mode=\"categorical\", subset=\"validation\", shuffle=False, seed=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3, transfer learning\n",
    "\n",
    "datagen= ImageDataGenerator(rescale=1/255,validation_split=.3)\n",
    "\n",
    "classifier=VGG16(weights=\"imagenet\", include_top=False, input_shape=(64,64,3))\n",
    "\n",
    "for layer in classifier.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "x=Flatten()(classifier.output)\n",
    "x=Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "model=Model(inputs=classifier.input, outputs=x)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "22/22 [==============================] - 69s 3s/step - loss: 1.1229 - accuracy: 0.4022 - val_loss: 0.9127 - val_accuracy: 0.6276\n",
      "Epoch 2/3\n",
      "22/22 [==============================] - 66s 3s/step - loss: 0.9218 - accuracy: 0.5656 - val_loss: 0.7545 - val_accuracy: 0.7318\n",
      "Epoch 3/3\n",
      "22/22 [==============================] - ETA: 0s - loss: 0.7297 - accuracy: 0.7143"
     ]
    }
   ],
   "source": [
    "total_sample= train_generator.n\n",
    "batch_size=128\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    "\n",
    "history= model.fit_generator(\n",
    "            train_generator, steps_per_epoch=int(total_sample/batch_size),\n",
    "            epochs=3,\n",
    "            validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
