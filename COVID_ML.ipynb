{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Lambda, Input, AveragePooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random\n",
    "#import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Covid', 'Edema', 'Enlarged_Cardiomediastinum', 'Fracture', 'Lung_Lesion', 'Lung_Opacity', 'No_Finding', 'Pleural_Other', 'Pneumonia', 'Pneumothorax', 'Support_Devices']\n"
     ]
    }
   ],
   "source": [
    "# Check filenames \n",
    "image_names=list(os.listdir(\"./Resources/images\"))\n",
    "image_names.sort()\n",
    "print(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No_Finding                    1898\n",
       "Atelectasis                    286\n",
       "Covid                          184\n",
       "Pneumothorax                   164\n",
       "Lung_Opacity                   156\n",
       "Edema                          155\n",
       "Support_Devices                154\n",
       "Consolidation                  145\n",
       "Enlarged_Cardiomediastinum     143\n",
       "Fracture                       142\n",
       "Cardiomegaly                   136\n",
       "Lung_Lesion                    127\n",
       "Pneumonia                      118\n",
       "Pleural_Other                   99\n",
       "Name: condition, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directory with Atelectasis\n",
    "atele_dir=os.path.join(\"./Resources/images/Atelectasis\")\n",
    "df =pd.DataFrame.from_records({\"file_name\":os.listdir(atele_dir),\"condition\": \"Atelectasis\"})\n",
    "for f in image_names[2:]:\n",
    "    folder_path=\"./Resources/images/\" + f\n",
    "    temp_df= pd.DataFrame.from_records({\"file_name\":os.listdir(folder_path),\"condition\": f })\n",
    "    df=df.append(temp_df)\n",
    "    \n",
    "df[\"condition\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Atelectasis                   286\n",
       "Covid                         184\n",
       "Pneumothorax                  164\n",
       "Lung_Opacity                  156\n",
       "Edema                         155\n",
       "Support_Devices               154\n",
       "No_Finding                    150\n",
       "Consolidation                 145\n",
       "Enlarged_Cardiomediastinum    143\n",
       "Fracture                      142\n",
       "Cardiomegaly                  136\n",
       "Lung_Lesion                   127\n",
       "Pneumonia                     118\n",
       "Pleural_Other                  99\n",
       "Name: condition, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# balance classes - random Random Sampling No_Finding\n",
    "df_no_finding = df[df[\"condition\"]==\"No_Finding\"].sample(n=150, random_state=42)\n",
    "df_balanced = df[df[\"condition\"]!=\"No_Finding\"].append(df_no_finding)\n",
    "df_balanced[\"condition\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced[\"file_name\"] = \"./Resources/images/All/\"+df_balanced[\"file_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate into train/test \n",
    "X=df_balanced[\"file_name\"]\n",
    "y=df_balanced[\"condition\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129    ./Resources/images/All/patient04362-study8-vie...\n",
      "130    ./Resources/images/All/patient04689-study1-vie...\n",
      "90     ./Resources/images/All/patient02661-study5-vie...\n",
      "107    ./Resources/images/All/patient03108-study1-vie...\n",
      "127    ./Resources/images/All/patient04362-study10-vi...\n",
      "                             ...                        \n",
      "65     ./Resources/images/All/patient14737-study1-vie...\n",
      "46     ./Resources/images/All/patient01343-study2-vie...\n",
      "81     ./Resources/images/All/patient03011-study1-vie...\n",
      "103    ./Resources/images/All/patient09147-study1-vie...\n",
      "109    ./Resources/images/All/patient01682-study3-vie...\n",
      "Name: file_name, Length: 1511, dtype: object\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "if K.image_data_format() == 'th':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not Series",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e182edb5ef9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 classes= [\"Covid\", \"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"Enlarged_Cardiomediastinum\", \"Fracture\", \n\u001b[0;32m     14\u001b[0m                           \"Lung_Lesion\", \"Lung_Opacity\", \"No_Finding\", \"Pleural_Other\", \"Pneumonia\", \"Pneumothorax\", \"Support_Devices\"],\n\u001b[1;32m---> 15\u001b[1;33m                 class_mode='categorical', shuffle=True, seed=30)\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Flow test images in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 959\u001b[1;33m         interpolation=interpolation)\n\u001b[0m\u001b[0;32m    960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m   def flow_from_dataframe(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m         **kwargs)\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mdirpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m             results.append(\n\u001b[0;32m    130\u001b[0m                 pool.apply_async(_list_valid_filenames_in_directory,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mdirpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m             results.append(\n\u001b[0;32m    130\u001b[0m                 pool.apply_async(_list_valid_filenames_in_directory,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\ntpath.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(path, *paths)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m# Join two (or more) paths.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb'\\\\'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not Series"
     ]
    }
   ],
   "source": [
    "img_width, img_height=200,200\n",
    "batch_size=128\n",
    "\n",
    "\n",
    "# Rescale images \n",
    "datagen= ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow training images in batches of 128 using train_data \n",
    "train_generator= datagen.flow_from_directory(\n",
    "                X_train,\n",
    "                target_size=(img_width,img_height),\n",
    "                batch_size=batch_size,\n",
    "                classes= [\"Covid\", \"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"Enlarged_Cardiomediastinum\", \"Fracture\", \n",
    "                          \"Lung_Lesion\", \"Lung_Opacity\", \"No_Finding\", \"Pleural_Other\", \"Pneumonia\", \"Pneumothorax\", \"Support_Devices\"],\n",
    "                class_mode='categorical', shuffle=True, seed=30)\n",
    "\n",
    "# Flow test images in \n",
    "\n",
    "datagen2=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "test_generator=datagen2.flow_from_directory(\n",
    "                X_test,\n",
    "                target_size=(img_width,img_height),\n",
    "                batch_size=batch_size,\n",
    "                classes= [\"Covid\", \"Atelectasis\", \"Cardiomegaly\", \"Consolidation\", \"Edema\", \"Enlarged_Cardiomediastinum\", \"Fracture\", \n",
    "                          \"Lung_Lesion\", \"Lung_Opacity\", \"No_Finding\", \"Pleural_Other\", \"Pneumonia\", \"Pneumothorax\", \"Support_Devices\"],\n",
    "                class_mode='categorical',subset=\"validation\", shuffle=True, seed=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN MODEL- conv-batch-maxpool-dropout\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32, kernel_size=3, activation=\"relu\", input_shape=(200,200,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(Dropout(.3))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(Dropout(.4))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(strides=(2,2)))\n",
    "model.add(Dropout(.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dropout(.4))\n",
    "\n",
    "model.add(Dense(14, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "\n",
    "from keras.callbacks import History\n",
    "history=History()\n",
    "\n",
    "Model.fit_generator(\n",
    "            train_generator, steps_per_epoch=900,\n",
    "            epochs=100, callbacks=[history],\n",
    "            validation_data=test_generator, \n",
    "            validation_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
