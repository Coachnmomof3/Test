{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "GoogleColab_COVID_ML.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lt8CVBL0OAV"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50 \n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Lambda, Input, AveragePooling2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf \n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import random\n",
        "#import cv2\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xQm4fstBuTIg",
        "outputId": "231bc2e1-0e34-4afc-b7ce-40cf3af173db"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L99dOLAb0vB3",
        "outputId": "8bc850e6-d4ce-4b86-8571-f5e8b7520adf"
      },
      "source": [
        "# Mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqfJ0n8h2Zp_"
      },
      "source": [
        "# Changing directory to images\n",
        "os.chdir(\"/content/drive/MyDrive/Data Analysis Bootcamp\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqiYPt-V0OAV",
        "outputId": "b45fff30-8c93-41f8-d3f4-ea390b17fe72"
      },
      "source": [
        "# Check Classes \n",
        "image_names=list(os.listdir(\"Resources/Images/Database\"))\n",
        "image_names.sort()\n",
        "print(image_names)\n",
        "class_number = len(image_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Covid', 'No_Finding', 'Pneumonia']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWMEFFWH0OAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d64654b-4b17-4686-d956-069fad54dad3"
      },
      "source": [
        "# Directory with Atelectasis\n",
        "atele_dir=os.path.join(\"Resources/Images/Database/Covid\")\n",
        "df =pd.DataFrame.from_records({\"file_name\":os.listdir(atele_dir),\"condition\": \"Covid\"})\n",
        "for f in image_names[1:]:\n",
        "    folder_path=\"Resources/Images/Database/\" + f\n",
        "    temp_df= pd.DataFrame.from_records({\"file_name\":os.listdir(folder_path),\"condition\": f })\n",
        "    df=df.append(temp_df)\n",
        "    \n",
        "df[\"condition\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Covid         184\n",
              "No_Finding    151\n",
              "Pneumonia     118\n",
              "Name: condition, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti7rsv5t0OAX"
      },
      "source": [
        "#Exporting Label CSV\n",
        "#df.to_csv(\"Labels.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwuEDPJf0OAX"
      },
      "source": [
        "# balance classes - random Random Sampling No_Finding\n",
        "#df_no_finding = df[df[\"condition\"]==\"No_Finding\"].sample(n=150, random_state=42)\n",
        "#df_balanced = df[df[\"condition\"]!=\"No_Finding\"].append(df_no_finding)\n",
        "#df_balanced[\"condition\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxmn5Z0M0OAX"
      },
      "source": [
        "#df_balanced[\"file_name\"] = \"Resources/Images/Classes/\"+df_balanced[\"file_name\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVe4Czei0OAX"
      },
      "source": [
        "# Settings\n",
        "batch_size = 16\n",
        "img_height, img_width = 256,256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggL4dMd70a8A",
        "outputId": "b8670471-fa15-41dd-9726-95fcd92bfdb0"
      },
      "source": [
        "data_dir = \"Resources/Images/Database/\"\r\n",
        "\r\n",
        "# Rescale images \r\n",
        "datagen= ImageDataGenerator(rescale=1/255,validation_split=.3,rotation_range=20,\r\n",
        "                           shear_range=.2,width_shift_range=0.1,height_shift_range=0.1,zoom_range=0.2)\r\n",
        "\r\n",
        "# Flow training images in batches of batch_size using train_data \r\n",
        "train_ds= datagen.flow_from_directory(\r\n",
        "                data_dir,\r\n",
        "                target_size=(img_width,img_height),\r\n",
        "                batch_size=batch_size,\r\n",
        "                subset=\"training\",\r\n",
        "                class_mode=\"categorical\", \r\n",
        "                classes= image_names,\r\n",
        "                shuffle=True, \r\n",
        "                seed=30)\r\n",
        "\r\n",
        "\r\n",
        "datagen2=ImageDataGenerator(rescale=1/255,validation_split=.3)\r\n",
        "\r\n",
        "val_ds=datagen2.flow_from_directory(\r\n",
        "                data_dir,\r\n",
        "                target_size=(img_width,img_height),\r\n",
        "                batch_size=batch_size,\r\n",
        "                classes= image_names,\r\n",
        "                class_mode=\"categorical\", \r\n",
        "                subset=\"validation\", \r\n",
        "                shuffle=True, \r\n",
        "                seed=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 318 images belonging to 3 classes.\n",
            "Found 135 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPL1NJ_r0OAX"
      },
      "source": [
        "#data_dir = \"Resources/Images/Classes/\"\n",
        "#train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "#  data_dir,\n",
        "#  validation_split=0.2,\n",
        "#  subset=\"training\",\n",
        "#  seed=123,\n",
        "#  image_size=(img_height, img_width),\n",
        "#  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDias_Db0OAX"
      },
      "source": [
        "#val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "#  data_dir,\n",
        "#  validation_split=0.2,\n",
        "#  subset=\"validation\",\n",
        "#  seed=123,\n",
        "#  image_size=(img_height, img_width),\n",
        "#  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "_GJdffTzxvy8",
        "outputId": "32014c6b-84c9-4560-8810-d900352f0564"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\r\n",
        "  model = tf.keras.Sequential([\r\n",
        "                               Conv2D(32, 3, activation='relu'),\r\n",
        "                               MaxPooling2D(),\r\n",
        "                               Conv2D(32, 3, activation='relu'),\r\n",
        "                               MaxPooling2D(),\r\n",
        "                               Conv2D(32, 3, activation='relu'),\r\n",
        "                               MaxPooling2D(),\r\n",
        "                               Dense(img_height, activation='relu'),\r\n",
        "                               Flatten(),\r\n",
        "                               Dense(class_number, activation='softmax')\r\n",
        "                               ])\r\n",
        "  model.compile(\r\n",
        "  optimizer='adam',\r\n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\r\n",
        "  metrics=['accuracy']\r\n",
        "  )\r\n",
        "\r\n",
        "  history = model.fit(\r\n",
        "  train_ds,\r\n",
        "  validation_data=val_ds,\r\n",
        "  epochs=10,\r\n",
        "  verbose=1\r\n",
        "  )\r\n",
        "\r\n",
        "  plt.plot(history.history['accuracy'])\r\n",
        "  plt.plot(history.history['val_accuracy'])\r\n",
        "  plt.title('model accuracy')\r\n",
        "  plt.ylabel('accuracy')\r\n",
        "  plt.xlabel('epoch')\r\n",
        "  plt.legend(['train', 'test'], loc='upper left')\r\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "20/20 [==============================] - 13s 659ms/step - loss: 1.1478 - accuracy: 0.3836 - val_loss: 1.1440 - val_accuracy: 0.4074\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 13s 646ms/step - loss: 1.1458 - accuracy: 0.4057 - val_loss: 1.1440 - val_accuracy: 0.4074\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 13s 627ms/step - loss: 1.1458 - accuracy: 0.4057 - val_loss: 1.1440 - val_accuracy: 0.4074\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 12s 624ms/step - loss: 1.1458 - accuracy: 0.4057 - val_loss: 1.1440 - val_accuracy: 0.4074\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 12s 622ms/step - loss: 1.1458 - accuracy: 0.4057 - val_loss: 1.1440 - val_accuracy: 0.4074\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 13s 634ms/step - loss: 1.1458 - accuracy: 0.4057 - val_loss: 1.1440 - val_accuracy: 0.4074\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 13s 628ms/step - loss: 1.1458 - accuracy: 0.4057 - val_loss: 1.1440 - val_accuracy: 0.4074\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 13s 640ms/step - loss: 1.1458 - accuracy: 0.4057 - val_loss: 1.1440 - val_accuracy: 0.4074\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 13s 647ms/step - loss: 1.1458 - accuracy: 0.4057 - val_loss: 1.1440 - val_accuracy: 0.4074\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 13s 633ms/step - loss: 1.1458 - accuracy: 0.4057 - val_loss: 1.1440 - val_accuracy: 0.4074\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep5uy9utz2qo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "outputId": "51e2516b-893a-48bc-9375-601e70ed19c8"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\r\n",
        "  VGG16_model = tf.keras.Sequential([\r\n",
        "                                     VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(img_height, img_width, 3))),\r\n",
        "                                     MaxPooling2D(),\r\n",
        "                                     Dense(img_height, activation='relu'),\r\n",
        "                                     Flatten(),\r\n",
        "                                     Dense(class_number, activation='softmax')\r\n",
        "                                     ])\r\n",
        "\r\n",
        "  VGG16_model.compile(\r\n",
        "      optimizer='adam',\r\n",
        "      loss=tf.losses.CategoricalCrossentropy(from_logits=True),\r\n",
        "      metrics=['accuracy']\r\n",
        "      )\r\n",
        "  \r\n",
        "  VGG16_model_history = VGG16_model.fit(\r\n",
        "      train_ds,\r\n",
        "      validation_data=val_ds,\r\n",
        "      epochs=50,\r\n",
        "      verbose=1\r\n",
        "      )\r\n",
        "  plt.plot(VGG16_model_history.history['accuracy'])\r\n",
        "  plt.plot(VGG16_model_history.history['val_accuracy'])\r\n",
        "  plt.title('model accuracy')\r\n",
        "  plt.ylabel('accuracy')\r\n",
        "  plt.xlabel('epoch')\r\n",
        "  plt.legend(['train', 'test'], loc='upper left')\r\n",
        "  plt.show()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "20/20 [==============================] - 14s 714ms/step - loss: 1.2257 - accuracy: 0.3176 - val_loss: 1.2181 - val_accuracy: 0.3333\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 14s 690ms/step - loss: 1.2181 - accuracy: 0.3333 - val_loss: 1.2181 - val_accuracy: 0.3333\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 14s 684ms/step - loss: 1.2181 - accuracy: 0.3333 - val_loss: 1.2181 - val_accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 14s 676ms/step - loss: 1.2181 - accuracy: 0.3333 - val_loss: 1.2181 - val_accuracy: 0.3333\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 14s 680ms/step - loss: 1.2181 - accuracy: 0.3333 - val_loss: 1.2181 - val_accuracy: 0.3333\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 13s 672ms/step - loss: 1.2181 - accuracy: 0.3333 - val_loss: 1.2181 - val_accuracy: 0.3333\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 14s 678ms/step - loss: 1.2181 - accuracy: 0.3333 - val_loss: 1.2181 - val_accuracy: 0.3333\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 14s 681ms/step - loss: 1.2181 - accuracy: 0.3333 - val_loss: 1.2181 - val_accuracy: 0.3333\n",
            "Epoch 9/50\n",
            "11/20 [===============>..............] - ETA: 5s - loss: 1.1951 - accuracy: 0.3563"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-1dde0fece246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m       )\n\u001b[1;32m     22\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iUCglMez5G9"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\r\n",
        "  ResNet50_model = tf.keras.Sequential([\r\n",
        "                                     ResNet50(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(img_height, img_width, 3))),\r\n",
        "                                     MaxPooling2D(),\r\n",
        "                                     Dense(img_height, activation='relu'),\r\n",
        "                                     Flatten(),\r\n",
        "                                     Dense(class_number, activation='softmax')\r\n",
        "                                     ])\r\n",
        "\r\n",
        "  ResNet50_model.compile(\r\n",
        "      optimizer='adam',\r\n",
        "      loss=tf.losses.CategoricalCrossentropy(from_logits=True),\r\n",
        "      metrics=['accuracy']\r\n",
        "      )\r\n",
        "  \r\n",
        "  ResNet50_model.fit(\r\n",
        "      train_ds,\r\n",
        "      validation_data=val_ds,\r\n",
        "      epochs=50,\r\n",
        "      verbose=1\r\n",
        "      ),guijhyhujio,.ñ,gygyuigfyyygfsq4qdrftvybvtsfrdrdq222222"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlBynWPnz5KD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1rCrd3Rz5M1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}